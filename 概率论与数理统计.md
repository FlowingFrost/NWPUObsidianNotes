---
cssclasses:
---
目录插件 链接插件

[线上课程](https://www.icourse163.org/course/NWPU1460966164?tid=1465425575)

## 第一章 随机事件及其概率

### 第一节 随机事件的概念

#### 一、概率论的诞生及应用

1. **发展历史（3个阶段）**
   - **古典概率论**（17-18世纪）
   - **近代概率论**（19世纪）
   - **现代概率论**（20世纪-至今）

17世纪中叶，在误差、人口统计、人寿保险等范畴中，需要整理和研究大量的随机数据资料，于是孕育出一种专门研究大量随机现象的规律性的数学学科。但当时刺激数学家们首先思考概率论的问题，却是来自赌博者的问题。

**古典概率论**：1654年，法国，帕斯卡向费马提出赌博问题，两人一起对此问题进行深入探讨，最后他们各自给出了正确的解法，并由此奠定了古典概率论的基础。3年后，即1657年，荷兰数学家惠根斯亦用自己的方法解决了这一问题，更写成了《论赌博中的计算》---概率论最早的论著。他们3人提出的解法中，都涉及了同样一个概念：数学期望(mathematical expectation)。

之后，对概率论这一学科做出贡献的是数学家族——伯努利家族。雅可布·伯努利花了20年时光，将全部心血倾注到数学研究中，终于将"大数定律"这个定理证实。

**近代概率论**：19世纪，法国数学家拉普拉斯，《概率的分析理论》（1812）---一部继往开来的作品。

**现代概率论**：20世纪，苏联数学家柯尔莫哥洛夫(A. H. Колмогоров 1903-1987)《概率论基础》（1933）首次给出概率的严密公理化体系，成为现代概率论的基础，使概率论成为严谨的数学分支。

2. **概率论的应用**
   现在，概率论与以它为基础的数理统计一起，在自然科学，社会科学，工程技术，军事科学及工农业生产等诸多领域都起着重要的作用。卫星上天，导弹巡航，飞机制造，宇宙飞船遨游太空等都有概率论的一份功劳；海洋探险，考古研究等离不开概率统计；电子技术发展，影视文化的进步等同概率统计也是密不可分的。

#### 二、随机现象

自然界所观察到的现象主要有：确定性现象，随机现象。

1. **确定性现象**：在一定条件下可以准确预言结果的现象。又称必然现象。
   - "在1个标准大气压下100度的水必定沸腾"
   - "恒定外力作用下，作匀速直线运动的物体仍然作匀速直线运动"
   - "没有外力作用下，向上抛一颗石子必然下落"
   - "函数在间断点处不存在导数"等

   特征：条件完全决定结果。自然科学的很多学科就是专门研究和认识这种必然性的，寻求这类必然现象的因果关系，把握它们之间的数量规律。

2. **随机现象**：在基本条件完全相同的情况下，可能发生也可能不发生的现象。
   - 实例1："在相同条件下掷一枚均匀的硬币,观察正反两面出现的情况"。结果有可能出现正面（数字面）也可能出现反面。
   - 实例2："在相同条件下生产同一种零件，观察它们的尺寸"。结果："它们的尺寸总会有一点差异"。
   - 实例3："抛掷一枚骰子,观察出现的点数"。结果有可能为："1", "2", "3", "4", "5" 或 "6"。
   - 实例4："从一批含有正品和次品的产品中任意抽取一个产品"。其结果可能为:正品、次品。
   - 实例5："过马路交叉口时,可能遇上各种颜色的交通指挥灯"。
   - 实例6："一只灯泡的寿命"可长可短。

   特征：条件不能完全决定结果。

3. **随机现象的分类**
   - 个别随机现象：原则上不能在相同条件下重复出现（例6）
   - 大量随机现象：在相同条件下可以重复出现（例1-5）

注意：
- 随机现象揭示了条件和结果之间的非确定性联系, 其数量关系无法用函数加以描述
- 随机现象从表面上看，似乎杂乱无章, 没有规律。但实践证明, 如果同类随机现象大量重复出现, 结果就呈现出一定的规律性，这种规律性是由大量同类随机现象呈现出来的一种集体规律性，随着观察次数的增多而愈加明显，称之为统计规律性。

概率论 --- 研究随机现象数量规律的数学学科。数理统计 --- 以概率论为基础，研究大量随机现象的统计规律性。

#### 三、随机试验

1. **问题的提出**：如何来研究随机现象？随机现象是通过随机试验来研究的。

2. **定义**：在概率论中, 把具有以下2个特征的试验称为随机试验。
   - 允许在相同的条件下重复地进行
   - 每次试验的结果具有随机性，即结果不一定相同。试验之前不能确定哪一个结果会出现，但能事先明确试验的所有可能结果。

实例："抛掷一枚硬币, 观察正面, 反面出现的情况"。
   - 试验可以在相同的条件下重复地进行
   - 试验的所有可能结果: 正面，反面
   - 进行一次试验之前不能确定哪一个结果会出现。故为随机试验。

同理可知下列试验都为随机试验：
   - "抛掷一枚骰子, 观察出现的点数"
   - "从一批产品中, 依次任选三件, 记录出现正品与次品的件数"
   - "记录某公共汽车站某日上午某时刻的等车人数"
   - "考察某地区10月份的平均气温"
   - "从一批灯泡中任取一只, 测试其寿命"

注：
- 随机试验简称试验, 是一个广泛的术语。它包括各种各样的科学实验, 也包括对客观事物进行的"调查"、"观察"、或"测量"等。
- 随机试验通常用E来表示。

#### 四、样本空间 样本点

现代集合论为表述随机试验的所有可能结果提供了方便的工具。
问题：如何去表述随机试验的所有可能结果？

1. **问题**

2. **定义**：随机试验E的所有可能结果组成的集合称为E的样本空间, 记为Ω。
   样本空间的元素, 即试验E的每一个(最简单的不能再分解的)可能结果, 称为样本点，记作ω。

例1：写出下列随机试验的样本空间。
   1) 将一枚硬币连抛N次,观察正面出现的次数。
      Ω₁ = {0,1,2,3,...,N}
   2) 抛掷一枚骰子, 观察出现的点数。
      Ω₂ = {1,2,3,4,5,6}
   3) 从一批产品中,依次任选三件,记录出现正品与次品的情况。
      设C→正品，Z→次品，则
      Ω₃ = {CCC, CZC, CCZ, ZCC, CZZ, ZCZ, ZZC, ZZZ}
   4) 记录某公共汽车站某日上午某时刻的等车人数。
      Ω₄ = {0,1,2,...}
   5) 考察某地区12月份的平均气温。
      Ω₅ = {t|T₁ < t < T₂}，其中t为平均温度
   6) 从一批灯泡中任取一只, 测试其寿命。
      Ω₆ = {t|t ≥ 0}，其中t为灯泡的寿命

注：
- 试验不同, 对应的样本空间也不同。
- 同一试验, 若试验目的不同, 则对应的样本空间也不同。
  对于同一试验: "将一枚硬币抛掷三次"。
  若观察正面H、反面T出现的情况, 则样本空间为
  Ω = {HHH, HHT, HTH, THH, HTT, TTH, THT, TTT}
  若观察出现正面的次数, 则样本空间为
  Ω = {0, 1, 2, 3}

- 建立样本空间, 事实上就是建立随机现象的数学模型。因此, 一个样本空间可以概括许多内容大不相同的实际问题。
  如：只包含两个样本点的样本空间Ω = {H,T}，它既可以作为抛掷硬币出现正面或出现反面的模型, 也可以作为产品检验中合格与不合格的模型, 又能用于排队现象中有人排队与无人排队的模型等。

所以在具体问题的研究中, 描述随机现象的第一步就是建立样本空间。

#### 五、随机事件（random event）的概念

1. **问题**：在随机试验中，我们往往会关心某个或某些结果是否会出现。这就是随机事件。如何描述满足某些条件的样本点?

2. **基本概念**
   - **随机事件**：随机试验E的样本空间Ω的子集称为E的随机事件, 简称事件。即随机事件是满足某些条件的样本点所组成的集合。
   
   实例：抛掷一枚骰子, 观察出现的点数。试验中, 骰子"出现1点", "出现2点", …, "点数不大于4", "点数为偶数"等都为随机事件。
   
   随机事件发生——组成随机事件的其中一个样本点出现。

   - **基本事件**：仅由一个样本点组成的单点集。它是随机试验的直接结果, 每次试验必定发生且只可能发生一个基本事件。
     如："出现1点", "出现2点", …, "出现6点"。
   
   - **复合事件**：由若干个样本点组成的点集。
     如："点数不大于4", "点数为偶数"。
   
   - **必然事件**：随机试验中必然会出现的结果。
     如：上述试验中"点数不大于6"就是必然事件。
   
   - **不可能事件**：随机试验中不可能出现的结果。
     如：上述试验中"点数大于6"就是不可能事件。
     必然事件的对立面是不可能事件, 不可能事件的对立面是必然事件, 它们互称为对立事件。记为∅。

3. **几点说明**
   - 随机事件可简称为事件, 并以大写英文字母A, B, C, … 来表示事件。
     例如：抛掷一枚骰子, 观察出现的点数。可设A = "点数不大于4", B = "点数为奇数"等等。

   - 随机试验、样本空间与随机事件的关系：每一个随机试验相应地有一个样本空间, 样本空间的子集就是随机事件。

### 第二节 随机事件的运算和关系

#### 一、随机事件间的运算

1. **和事件（并事件）**：A∪B，"A, B至少发生一个"也是一个事件。称A∪B为事件A与事件B的和事件。
   显然{ω|ω∈A或ω∈B}。
   
   实例：某种产品的合格与否是由该产品的长度与直径是否合格所决定, 因此"产品不合格"是"长度不合格"与"直径不合格"的并。

2. **积事件（交事件）**：A∩B或AB，"A, B同时发生"也是一个事件。称A∩B或AB为事件A与事件B的积事件。
   显然{ω|ω∈A且ω∈B}。
   
   实例：续上："产品合格"是"长度合格"与"直径合格"的交或积事件。

3. **差事件**：A-B，由事件A发生而事件B不发生所组成的事件称为事件A与B的差事件。
   
   实例："长度合格但直径不合格"是"长度合格"与"直径合格"的差。

推广：
- A₁∪A₂∪...∪Aₙ = ∪ᵢ₌₁ⁿ Aᵢ 表示A₁, A₂, ..., Aₙ至少有一个发生
- A₁∪A₂∪... = ∪ᵢ₌₁^∞ Aᵢ 表示A₁, A₂, ...至少有一个发生
- A₁∩A₂∩...∩Aₙ = ∩ᵢ₌₁ⁿ Aᵢ 表示A₁, A₂, ..., Aₙ同时发生
- A₁∩A₂∩... = ∩ᵢ₌₁^∞ Aᵢ 表示A₁, A₂, ...同时发生

#### 二、随机事件间的关系

1. **包含关系**：若事件A发生, 必然导致B发生, 则称事件B包含事件A, 记作B ⊃ A或A ⊂ B。
   
   实例："长度不合格"必然导致"产品不合格"，所以"产品不合格"包含"长度不合格"。

2. **相等关系**：如果事件B包含事件A, 同时事件A包含事件B, 则称事件A与事件B相等, 记作A = B。

3. **互斥（互不相容）**：若事件A的发生必然导致事件B不发生, B的发生也必然导致A不发生, 则称事件A与B互斥（或互不相容）, 即AB = ∅。
   
   实例1：抛掷一枚硬币,"出现花面"与"出现字面"是互不相容的两个事件。
   实例2：抛掷一枚骰子, 观察出现的点数。"骰子出现1点"与"骰子出现2点"互斥。

   注：
   - 当A∩B = ∅时, 可将A∪B记为"直和"形式A+B，即A∪B = A+B (当AB = ∅时)。
   - 任意事件A与不可能事件∅为互斥。

4. **互逆（对立）**：设A表示"事件A发生", 则"事件A不发生"称为事件A的对立事件或逆事件。记作Ā。
   若A与B互逆, 则有A∪B = Ω 且AB = ∅。A = B̄。

   实例："骰子出现1点"与"骰子不出现1点"

注：
- 互斥与互逆的关系：互逆 → 互斥，但互斥不一定互逆。
- 必然事件Ω与不可能事件∅互逆。

#### 三、运算定律

1. **交换律**：
   - A∪B = B∪A
   - AB = BA

2. **结合律**：
   - (A∪B)∪C = A∪(B∪C)
   - (AB)C = A(BC)

3. **分配律**：
   - A∪(B∩C) = (A∪B)∩(A∪C)
   - A∩(B∪C) = (A∩B)∪(A∩C)

4. **对偶律（De Morgan定理）**：
   - A∪B = Ā∩B̄，意义："A, B至少有一个发生"的对立事件是"A, B均不发生"
   - A∩B = Ā∪B̄，意义："A, B均发生"的对立事件是"A, B至少有一个不发生"

   推广：
   - ∪ᵢ₌₁ⁿ Aᵢ = ∩ᵢ₌₁ⁿ Āᵢ
   - ∩ᵢ₌₁ⁿ Aᵢ = ∪ᵢ₌₁ⁿ Āᵢ

5. **其它一些性质**：
   - 若A ⊂ B, 则A∪B = B, AB = A
   - A∪∅ = A, A∩∅ = ∅
   - A∪Ω = Ω, A∩Ω = A
   - A∪Ā = Ω, A∩Ā = ∅

### 第三节 频率与概率

（注：根据PPT文件内容，这里缺少第3节的详细内容，我们继续看条件概率部分）

### 第四节 条件概率、全概率公式与贝叶斯公式

#### 一、条件概率

1. **问题的引入**
   甲乙两台车床加工同一种机械零件，质量表如下：
   |        | 正品数 | 次品数 | 合计 |
   |--------|--------|--------|------|
   | 甲车床 | 35     | 5      | 40   |
   | 乙车床 | 50     | 10     | 60   |
   | 总计   | 85     | 15     | 100  |

   从这100个零件中任取一个，求下列事件的概率：
   (1) 取出的一个为正品；P(A) = 85/100 = 0.85
   (2) 取出的一个为甲车床加工的零件；P(B) = 40/100 = 0.40
   (3) 取出的一个为甲车床加工的正品；P(AB) = 35/100 = 0.35
   (4) 已知取出的一个为甲车床加工的零件，其为正品。

   设C = "取出的一个为甲车床加工的正品"，则在已知B发生的条件下，A发生的概率为：
   P(A|B) = P(AB)/P(B) = (35/100)/(40/100) = 35/40 = 0.875

2. **定义**：设A, B是两个事件，且P(B) > 0, 则称
   P(A|B) = P(AB)/P(B)
   为事件B发生的条件下，事件A发生的条件概率。

   注：计算P(A|B)的方法：
   - ① 样本空间缩减法；（适用于后面要讲的乘法公式中条件概率的计算，一般直接计算）
   - ② 用定义

3. **条件概率的性质**
   - (1) 非负性：0 ≤ P(A|B) ≤ 1
   - (2) 规范性：P(Ω|B) = 1
   - (3) 可列可加性：对于两两互斥的事件序列A₁, A₂, ...，有P(∪ᵢAᵢ|B) = ∑ᵢP(Aᵢ|B)

4. **乘法公式**
   若P(B) > 0, 则有P(AB) = P(B)P(A|B)
   若P(A) > 0, 则有P(AB) = P(A)P(B|A)
   
   推广：设A, B, C为事件，且P(AB) > 0, 则
   P(ABC) = P(A)P(B|A)P(C|AB)
   
   一般地，设A₁, A₂, ..., Aₙ是n个事件，若P(A₁A₂...Aₙ₋₁) > 0, 则
   P(A₁A₂...Aₙ) = P(A₁)P(A₂|A₁)P(A₃|A₁A₂)...P(Aₙ|A₁A₂...Aₙ₋₁)

#### 二、全概率公式

1. **样本空间的划分**：设Ω为试验E的样本空间，A₁, A₂, ..., Aₙ为E的一组事件，若
   - (1) AᵢAⱼ = ∅, i ≠ j, i, j = 1,2,...,n
   - (2) A₁∪A₂∪...∪Aₙ = Ω
   则称A₁, A₂, ..., Aₙ为样本空间Ω的一个划分。

2. **全概率公式**：设B为试验E的事件，A₁, A₂, ..., Aₙ为Ω的一个划分，且P(Aᵢ) > 0 (i=1,2,...,n)，则
   P(B) = P(A₁)P(B|A₁) + P(A₂)P(B|A₂) + ... + P(Aₙ)P(B|Aₙ) = ∑ᵢ₌₁ⁿ P(Aᵢ)P(B|Aᵢ)

   全概率公式的主要用处在于：它可以将一个复杂事件的概率计算问题，分解为若干个简单事件的概率计算问题，最后应用概率的可加性求出最终结果。

#### 三、贝叶斯公式

1. **定义**：设A₁, A₂, ..., Aₙ是样本空间Ω的一个划分，且P(Aᵢ) > 0 (i=1,2,...,n)，B为任一事件，P(B) > 0, 则
   P(Aᵢ|B) = P(Aᵢ)P(B|Aᵢ) / ∑ⱼ₌₁ⁿ P(Aⱼ)P(B|Aⱼ), i = 1,2,...,n

2. **贝叶斯公式的意义**：
   - 先验概率：P(Aᵢ)（在观察结果B之前对Aᵢ概率的估计）
   - 后验概率：P(Aᵢ|B)（在观察到结果B之后对Aᵢ概率的重新估计）
   - 后验概率比先验概率更有说服力，可以为进一步的决策提供依据。


## 第二章 随机变量及其分布

### 第一节 一维随机变量及其分布 (1)

#### 一、随机变量的定义

1. **随机变量的引入**
   如何更透彻地研究随机现象？用数学分析的方法研究随机现象。
   
   在很多随机试验中，我们关注的结果可以用数值来表示，但有些试验结果不是数值，如：
   - 非数量结果：颜色（红色、白色）、性别（男、女）等
   - 为了用数学分析方法研究随机现象，需要将样本空间和实数集建立对应关系，这就是随机变量的概念。

   **实例1**：在一装有红球、白球的袋中任摸一个球, 观察摸出球的颜色。
   可采用下列方法将非数量结果数量化：
   - 设Ω = {红色、白色}
   - 定义X(e) = {1, 当e = 红色; 0, 当e = 白色}
   - 这样便将非数量的Ω = {红色、白色}数量化了。

   **实例2**：抛掷骰子, 观察出现的点数。
   - Ω = {1, 2, 3, 4, 5, 6}
   - 样本点本身就是数量，恒等变换X(e) = e
   - X(1) = 1, X(2) = 2, ..., X(6) = 6
   - 且有P{X = i} = 1/6, i = 1,2,3,4,5,6

2. **随机变量的定义**
   **定义2.1**：设E是随机试验，其样本空间为Ω = {ω}。若对于每一个样本点ω ∈ Ω，都有唯一的实数值X(ω)与之对应，则称定义在Ω = {ω}上的单值实函数X(ω)为随机变量（r.v.），简记为X。

   常用X，Y，Z，…表示随机变量；用x, y, z, …表示X，Y，Z，…的取值。

   **注**：随机变量X与高等数学中的实函数有本质区别：
   - X是Ω → R上的映射，定义域：样本空间Ω，但是Ω不一定是实数集
   - X的自变量在随机试验中是随机出现的，导致X的取值是随机的，它的每一个可能取值都 有一定的概率

   **重要性质**：
   - 任何随机事件都可以通过随机变量来表示。即对于任意实数x, {X ≤ x}是随机事件
   - 对于随机变量, 我们常常关心它的取值

#### 二、分布函数及其性质

1. **分布函数的定义**
   **定义2.2**：称F(x) = P{X ≤ x}, -∞ < x < +∞为随机变量X的分布函数。
   
   记作X ～ F(x)或X ～ F_X(x)。

   **注**：
   - 如果将X看作数轴上随机点的坐标, 则分布函数F(x)的值表示X落在区间(-∞, x]的概率
   - 分布函数是一个普通的函数，正是通过它，我们可以用数学分析的工具来研究随机变量
   - X是随机变量, x是参变量。F(x)是随机变量X取值不大于x的概率

2. **分布函数的性质**
   一个函数F(x)是某个随机变量X的分布函数的充要条件是F(x)具有以下四条基本性质：
   
   (1) 有界性：对任意实数x，有0 ≤ F(x) ≤ 1
   (2) 单调性：F(x)是单调不减函数，即对任意x₁ < x₂，有F(x₁) ≤ F(x₂)
   (3) 极限性质：F(-∞) = lim[x→-∞] F(x) = 0，F(+∞) = lim[x→+∞] F(x) = 1
   (4) 右连续性：F(x)是右连续的，即对任意实数a，lim[x→a⁺] F(x) = F(a)

3. **重要公式**
   设F(x)是随机变量X的分布函数，则：
   - P{X ≤ b} = F(b) 
   - P{a < X ≤ b} = F(b) - F(a)
   - P{X > a} = 1 - F(a)
   - P{X < b} = F(b-0)（其中F(b-0)表示F(x)在点b处的左极限）
   - P{X = b} = F(b) - F(b-0)

**例题**：
设随机变量X的分布函数为F(x) = {0, x ≤ 0; A + Be^(-λx), x > 0}，其中λ > 0，求常数A, B。

解：由分布函数的性质，F(x)在(-∞, +∞)上右连续。
- 由F(+∞) = 1，得lim[x→+∞] (A + Be^(-λx)) = A = 1，所以A = 1
- 由右连续性，F(0) = lim[x→0⁺] F(x)，即0 = A + B，所以B = -1
- 因此F(x) = {0, x ≤ 0; 1 - e^(-λx), x > 0}

### 第一节 一维随机变量及其分布 (2)

#### 三、离散型随机变量

随机变量的分类：
- 离散型随机变量：所有取值可以逐个一一列举，如"抽验一批产品中次品的个数"，"电话交换台在一定时间内收到的呼叫次数"等
- 连续型随机变量：全部可能取值有无穷多，充满一个或几个区间，如"电视机的寿命"，"测量误差"等

1. **离散型随机变量的分布律**
   
   **定义**：若随机变量X的所有可能取值为x₁, x₂, ... 或x₁, x₂, ..., xₙ，对应的概率为p₁, p₂, ... 或p₁, p₂, ..., pₙ，即
   P{X = xₖ} = pₖ, k = 1,2,... 
   
   称上面两式为离散型随机变量X的分布律或分布列。
   
   一般用表格形式表示：
   | X    | x₁ | x₂ | ... | xₖ | ... |
   |------|----|----|-----|----|-----|
   | P    | p₁ | p₂ | ... | pₖ | ... |
   
   **注**：分布律中的pₖ必须满足：
   - (1) 非负性：pₖ ≥ 0, k = 1,2,...
   - (2) 规范性：∑ₖ pₖ = 1
   
   **例1**：设随机变量X的分布律为P{X = k} = aλᵏ/k!, k = 0,1,2,...，其中λ > 0, a为常数，试确定常数a。
   
   解：由规范性，∑ₖ₌₀^∞ P{X = k} = 1，即
   ∑ₖ₌₀^∞ aλᵏ/k! = a∑ₖ₌₀^∞ λᵏ/k! = ae^λ = 1
   
   所以a = e^(-λ)

2. **离散型随机变量分布律与分布函数的关系**
   
   (1) 若已知X的分布律P{X = xₖ} = pₖ, k = 1,2,...，则X的分布函数为：
   F(x) = P{X ≤ x} = ∑[xₖ ≤ x] P{X = xₖ} = ∑[xₖ ≤ x] pₖ
   
   (2) 若已知X的分布函数F(x)，则X的分布律为：
   P{X = xₖ} = pₖ = F(xₖ) - F(xₖ-0)
   
   其中F(xₖ-0)是F(x)在点xₖ处的左极限。

**例2**：一盒内装有5个乒乓球，其中2个旧的，3个新的，从中任取2个，求取得的新球个数X的分布律与分布函数，并计算P{0 < X ≤ 2}，P{0 ≤ X < 2}。

解：X = {取得的新球个数}，其分布律为：
P{X = k} = C₃ᵏC₂^(2-k)/C₅², k = 0,1,2

计算各项概率：
- P{X = 0} = C₃⁰C₂²/C₅² = 1×1/10 = 0.1
- P{X = 1} = C₃¹C₂¹/C₅² = 3×2/10 = 0.6
- P{X = 2} = C₃²C₂⁰/C₅² = 3×1/10 = 0.3

分布律表格：
| X | 0   | 1   | 2   |
|---|-----|-----|-----|
| P | 0.1 | 0.6 | 0.3 |

X的分布函数为：
F(x) = P{X ≤ x} = ∑[xₖ ≤ x] P{X = xₖ}

当x < 0时，F(x) = 0
当0 ≤ x < 1时，F(x) = P{X = 0} = 0.1
当1 ≤ x < 2时，F(x) = P{X = 0} + P{X = 1} = 0.1 + 0.6 = 0.7
当x ≥ 2时，F(x) = P{X = 0} + P{X = 1} + P{X = 2} = 0.1 + 0.6 + 0.3 = 1

所以分布函数为：
F(x) = {0, x < 0; 0.1, 0 ≤ x < 1; 0.7, 1 ≤ x < 2; 1, x ≥ 2}

计算概率：
- P{0 < X ≤ 2} = F(2) - F(0) = 1 - 0.1 = 0.9
- P{0 ≤ X < 2} = F(2-0) - F(0-0) = 0.7 - 0 = 0.7

#### 四、典型的离散型随机变量及其分布

1. **退化分布（单点分布）**：若随机变量X取常数值C的概率为1，即P{X = C} = 1，则称X服从退化分布。

2. **离散型均匀分布**：若X的分布律为P{X = xₖ} = 1/n, k = 1,2,...,n，这里x₁,x₂,...,xₙ各不相同，则称X服从离散型均匀分布。
   
   例如掷骰子试验，若记出现的点数为X，则X的可取值为1,2,3,4,5,6，X的分布律为P{X = i} = 1/6, i = 1,2,3,4,5,6。

3. **两点分布（伯努利分布）**：若X的分布律为
   P{X = k} = pᵏ(1-p)^(1-k), k = 0,1
   
   则称X服从(0-1)分布或两点分布。记为X ~ B(1,p)。
   
   两点分布是一种比较简单的分布，任何只有两种可能结果的随机现象，例如抛一次硬币出现"正面"或"反面"；做一次试验事件"A发生"或"A不发生"均可用来描述。

4. **二项分布**：若X的分布律为
   P{X = k} = Cₙᵏpᵏ(1-p)^(n-k), k = 0,1,2,...,n
   
   其中0 ≤ p ≤ 1，则称X服从参数为(n,p)的二项分布，记作X ~ B(n,p)。
   
   二项分布可以用来描述n重伯努利试验中事件A恰好发生k次的概率，是概率论中一种重要的分布。

   **例4**：某人进行射击，设每次射击的命中率为0.02，X设击中的次数为。则X ~ B(400, 0.02)。
   X的分布律为P{X = k} = C₄₀₀ᵏ(0.02)ᵏ(0.98)^(400-k), k = 0,1,2,...,400
   
   试求至少击中两次的概率：
   P{X ≥ 2} = 1 - P{X = 0} - P{X = 1}
   = 1 - (0.98)⁴⁰⁰ - C₄₀₀¹(0.02)(0.98)³⁹⁹
   = 1 - 0.98⁴⁰⁰ - 400×0.02×0.98³⁹⁹
   ≈ 0.9972

5. **泊松分布**：若X的分布律为
   P{X = k} = λᵏe^(-λ)/k!, k = 0,1,2,...,
   
   其中λ > 0，则称X服从参数为λ的泊松分布，记作X ~ P(λ)。

   泊松分布适合于描述单位时间内随机事件发生的次数，如某一服务设施在一定时间内到达的人数，电话交换机接到呼叫的次数，机器出现的故障数等等。

   **泊松定理**：设Xₙ ~ B(n, pₙ)，且lim[n→∞] npₙ = λ > 0，则对任意非负整数k，有
   lim[n→∞] P{Xₙ = k} = lim[n→∞] Cₙᵏpₙᵏ(1-pₙ)^(n-k) = λᵏe^(-λ)/k!

   这个定理表明泊松分布可作为二项分布的极限分布。当n很大，p很小，而λ = np适中时，可用泊松分布近似计算二项分布。

6. **几何分布**：若随机变量X的分布律为
   P{X = k} = p(1-p)^(k-1), k = 1,2,...
   
   则称X服从几何分布。
   
   几何分布可作为描述某个试验"首次成功"的概率模型。

   **例7**：设某批产品的次品率为p，对该批产品做有放回的抽样检查，直到第一次抽到一只次品为止(在此之前抽到的全是正品)，那么所抽到的产品数目X是一个随机变量，求X的分布律。
   
   解：X所取的可能值是1,2,3,...，设Aᵢ表示"抽到的第i个产品是正品"，则：
   P{X = k} = P{Ā₁Ā₂...Āₖ₋₁Aₖ}
   = P{Ā₁}P{Ā₂}...P{Āₖ₋₁}P{Aₖ}
   = (1-p)^(k-1)·p
   
   所以X服从几何分布。

7. **超几何分布**：设N件产品中有M件次品，从中任取n件，其中的次品数为X，则
   P{X = k} = CₘᵏC_(N-M)^(n-k) / Cₙ^N, k = 0,1,2,...,min{n,M}
   
   这里n < N，M < N。称X服从超几何分布，记作X ~ H(n,M,N)。
   
   在抽样检验中，二项分布对应有放回抽样；超几何分布对应无放回抽样。


## 第三章 多维随机变量及其分布

### 第一节 二维随机变量及其分布

#### 一、二维随机变量及其分布

在实际问题中，可能遇到多个随机变量的情形，如：
1. 射击问题中，对于弹着点需要横坐标和纵坐标描述
2. 人的基本特征需要考虑性别、身高、体重等
3. 评价产品的质量，可能有多个评价指标如尺寸、外形等

**定义**：由n个随机变量X₁, X₂, ..., Xₙ构成的向量X = (X₁, X₂, ..., Xₙ)称为n维随机变量，也称为n维随机向量。

**n维随机向量的分布函数**：称F(x₁, x₂, ..., xₙ) = P{X₁ ≤ x₁, X₂ ≤ x₂, ..., Xₙ ≤ xₙ}为随机向量(X₁, X₂, ..., Xₙ)的分布函数或联合分布函数。

当n=2时，二维分布函数F(x,y) = P{X ≤ x, Y ≤ y}表示随机点(X,Y)落在平面区域D = (-∞,x]×(-∞,y] = {(u,v)|u ≤ x, v ≤ y}内的概率。

#### 二、二维分布函数F(x,y)的性质

1. **有界性**：对任意实数x, y，有0 ≤ F(x,y) ≤ 1
2. **单调性**：F(x,y)分别对x和y单调非降，即当x₁ ≤ x₂时，F(x₁,y) ≤ F(x₂,y)；当y₁ ≤ y₂时，F(x,y₁) ≤ F(x,y₂)
3. **极限性质**：
   - F(-∞,y) = lim[x→-∞] F(x,y) = 0
   - F(x,-∞) = lim[y→-∞] F(x,y) = 0
   - F(-∞,-∞) = lim[x→-∞,y→-∞] F(x,y) = 0
   - F(+∞,+∞) = lim[x→+∞,y→+∞] F(x,y) = 1
4. **右连续性**：F(x,y)分别关于x和y右连续，即F(x,y) = F(x+0,y)，F(x,y) = F(x,y+0)
5. **非负性**：对于x₁ < x₂, y₁ < y₂，有F(x₂,y₂) - F(x₁,y₂) - F(x₂,y₁) + F(x₁,y₁) ≥ 0，这表示随机点(X,Y)落在矩形区域{x₁ < X ≤ x₂, y₁ < Y ≤ y₂}内的概率非负。

#### 三、二维离散型随机变量

**定义**：若二维随机变量(X,Y)的分量X, Y均为离散型随机变量，则称(X,Y)为二维离散型随机变量。

**1. 分布律**：若(X,Y)的所有可能取值为(xᵢ, yⱼ)，i,j = 1,2,...，
则P{X = xᵢ, Y = yⱼ} = pᵢⱼ，称{pᵢⱼ}为(X,Y)的分布律。

分布律可以用表格形式表示：

| Y\X  | x₁   | x₂   | ... | xᵢ   | ... |
|------|------|------|-----|------|-----|
| y₁   | p₁₁  | p₁₂  | ... | p₁ᵢ  | ... |
| y₂   | p₂₁  | p₂₂  | ... | p₂ᵢ  | ... |
| ...  | ...  | ...  | ... | ...  | ... |
| yⱼ   | pⱼ₁  | pⱼ₂  | ... | pᵢⱼ  | ... |
| ...  | ...  | ...  | ... | ...  | ... |

其中pᵢⱼ满足：
- (1) 非负性：pᵢⱼ ≥ 0，i,j = 1,2,...
- (2) 规范性：∑ᵢ∑ⱼ pᵢⱼ = 1

**分布函数**：F(x,y) = ∑[xᵢ≤x, yⱼ≤y] pᵢⱼ

#### 四、二维连续型随机变量

**定义**：若存在非负可积函数p(x,y)，对于二维随机变量(X,Y)的二元分布函数F(x,y)，对任意实数x,y可表示为：
F(x,y) = ∫∫[(-∞,x]×(-∞,y)] p(u,v)dudv = ∫[−∞,x]∫[−∞,y] p(u,v)dudv

则称(X,Y)为二维连续型随机变量，p(x,y)称为(X,Y)的联合密度函数。

**性质**：
1. **非负性**：p(x,y) ≥ 0
2. **规范性**：∫[−∞,+∞]∫[−∞,+∞] p(x,y)dxdy = 1
3. **概率计算**：设G是xOy平面上的一个区域，则(X,Y)落在区域G内的概率为：
   P{(X,Y)∈G} = ∫∫[G] p(x,y)dxdy
4. **密度函数与分布函数的关系**：若p(x,y)在点(x,y)连续，则有：
   ∂²F(x,y)/∂x∂y = p(x,y)

**例题**：设(X,Y)的分布密度为p(x,y) = {e^(-(x+y)), x>0,y>0; 0, 其他}

(1) 求F(x,y)
(2) 求(X,Y)落在区域D内的概率，其中D为三角形区域

解：
(1) 当x > 0, y > 0时，
F(x,y) = ∫[0,x]∫[0,y] e^(-(u+v))dvdu = ∫[0,x] e^(-u)du ∫[0,y] e^(-v)dv = (1-e^(-x))(1-e^(-y))

所以F(x,y) = {(1-e^(-x))(1-e^(-y)), x>0,y>0; 0, 其他}

(2) P{(X,Y)∈D} = ∫∫[D] e^(-(x+y))dxdy，根据具体区域D进行积分计算。

#### 五、常用分布

1. **均匀分布**：设D是平面上的有界区域，其面积为S，若
   p(x,y) = {1/S, (x,y)∈D; 0, 其他}
   
   则称(X,Y)在D上服从均匀分布。

2. **二维正态分布**：若(X,Y)具有密度函数
   p(x,y) = (1/(2πσ₁σ₂√(1-ρ²))) × exp{-1/[2(1-ρ²)] × [((x-μ₁)/σ₁)² - 2ρ((x-μ₁)/σ₁)((y-μ₂)/σ₂) + ((y-μ₂)/σ₂)²]}
   
   其中μ₁, μ₂, σ₁>0, σ₂>0, -1<ρ<1均为常数，则称(X,Y)服从参数为(μ₁,μ₂,σ₁²,σ₂²,ρ)的二维正态分布，记为(X,Y)~N(μ₁,μ₂,σ₁²,σ₂²,ρ)。

### 第二节 边缘分布

#### 一、边缘分布函数

如果(X,Y)是一个二维随机变量，则它的分量X(或者Y)是一维随机变量。我们称X(或者Y)的分布为X(或者Y)关于二维随机变量(X,Y)的边缘分布。

**定义**：设F(x,y)是随机变量(X,Y)的分布函数，
- 称F_X(x) = F(x,+∞)为X关于(X,Y)的边缘分布函数
- 称F_Y(y) = F(+∞,y)为Y关于(X,Y)的边缘分布函数

即P{X≤x} = P{X≤x, Y≤+∞} = F(x,+∞)，P{Y≤y} = P{X≤+∞, Y≤y} = F(+∞,y)

#### 二、离散型随机变量的边缘分布律

设二维离散型随机变量(X,Y)的联合分布律为P{X = xᵢ, Y = yⱼ} = pᵢⱼ，i,j = 1,2,...

**定义**：
- 称pᵢ• = ∑[j] pᵢⱼ = P{X = xᵢ}，i = 1,2,... 为X关于(X,Y)的边缘分布律
- 称p•ⱼ = ∑[i] pᵢⱼ = P{Y = yⱼ}，j = 1,2,... 为Y关于(X,Y)的边缘分布律

从分布列表中直观地看，就是行和与列和：

| Y\X  | x₁   | x₂   | ... | Σ    |
|------|------|------|-----|------|
| y₁   | p₁₁  | p₁₂  | ... | p•₁  |
| y₂   | p₂₁  | p₂₂  | ... | p•₂  |
| ...  | ...  | ...  | ... | ...  |
| Σ    | p₁•  | p₂•  | ... | 1    |

#### 三、连续型随机变量的边缘分布

设p(x,y)为二维连续型随机变量(X,Y)的密度函数，则：

- X的边缘密度函数为：p_X(x) = ∫[−∞,+∞] p(x,y)dy
- Y的边缘密度函数为：p_Y(y) = ∫[−∞,+∞] p(x,y)dx

**例题**：设(X,Y)的分布密度为p(x,y) = {e^(-(x+y)), x>0,y>0; 0, 其他}

求X和Y的边缘概率密度函数。

解：
p_X(x) = ∫[−∞,+∞] p(x,y)dy = ∫[0,+∞] e^(-(x+y))dy = e^(-x)∫[0,+∞] e^(-y)dy = e^(-x)，x > 0

所以X的边缘密度为：p_X(x) = {e^(-x), x > 0; 0, x ≤ 0}

同理可得Y的边缘密度为：p_Y(y) = {e^(-y), y > 0; 0, y ≤ 0}

**重要注释**：由联合分布能推出边缘分布，但由边缘分布推不出联合分布。

对于二维正态分布(X,Y)~N(μ₁,μ₂,σ₁²,σ₂²,ρ)，其边缘分布是一元正态分布：
- X~N(μ₁,σ₁²)
- Y~N(μ₂,σ₂²)

这表明二维正态分布的边缘分布是一元正态分布，且边缘分布中的参数与二元正态分布中的常数ρ无关。

#### 四、随机变量的独立性

**定义**：设X,Y是两个随机变量，若对任意的x,y，有：
F(x,y) = F_X(x)F_Y(y)

即P{X≤x, Y≤y} = P{X≤x}P{Y≤y}，则称X,Y相互独立。

**对于离散型随机变量**：若对(X,Y)所有可能取值(xᵢ, yⱼ)，有：
P{X = xᵢ, Y = yⱼ} = P{X = xᵢ}P{Y = yⱼ}

即pᵢⱼ = pᵢ•p•ⱼ，则称X,Y相互独立。

**对于连续型随机变量**：若对任意的x,y，有：
p(x,y) = p_X(x)p_Y(y)

则称X,Y相互独立，其中p(x,y)是(X,Y)的联合概率密度，p_X(x)和p_Y(y)分别是X和Y的边缘概率密度。

**例题**：设(X,Y)的概率密度为p(x,y) = {xe^(-(x+y)), x>0,y>0; 0, 其他}

求边缘密度并判断X,Y是否独立。

解：
当x > 0时，p_X(x) = ∫[0,+∞] xe^(-(x+y))dy = xe^(-x)∫[0,+∞] e^(-y)dy = xe^(-x)

所以p_X(x) = {xe^(-x), x > 0; 0, x ≤ 0}

当y > 0时，p_Y(y) = ∫[0,+∞] xe^(-(x+y))dx = e^(-y)∫[0,+∞] xe^(-x)dx = e^(-y)

所以p_Y(y) = {e^(-y), y > 0; 0, y ≤ 0}

因为p(x,y) = xe^(-(x+y)) ≠ xe^(-x)·e^(-y) = p_X(x)p_Y(y)，所以X与Y不独立。

#### 五、条件分布

**问题的提出**：在实际问题中，有时需要在一个随机变量取一定值的条件下，研究另一个随机变量的分布情况。

**1. 离散型随机变量的条件分布**

设(X,Y)是二维离散型随机变量，其联合分布律为P{X = xᵢ, Y = yⱼ} = pᵢⱼ。

对于固定的j，若P{Y = yⱼ} = p•ⱼ > 0，则称：
P{X = xᵢ | Y = yⱼ} = P{X = xᵢ, Y = yⱼ}/P{Y = yⱼ} = pᵢⱼ/p•ⱼ，i = 1,2,...

为在Y = yⱼ条件下X的条件分布律。

对于固定的i，若P{X = xᵢ} = pᵢ• > 0，则称：
P{Y = yⱼ | X = xᵢ} = P{X = xᵢ, Y = yⱼ}/P{X = xᵢ} = pᵢⱼ/pᵢ•，j = 1,2,...

为在X = xᵢ条件下Y的条件分布律。

**2. 连续型随机变量的条件分布**

设(X,Y)是二维连续型随机变量，其联合概率密度为p(x,y)，边缘概率密度为p_X(x)和p_Y(y)。

对于固定的y，若p_Y(y) > 0，则称：
p_{X|Y}(x|y) = p(x,y)/p_Y(y)

为在Y = y条件下X的条件概率密度。

相应地，条件分布函数为：
F_{X|Y}(x|y) = P{X ≤ x | Y = y} = ∫[−∞,x] p_{X|Y}(u|y)du = ∫[−∞,x] p(u,y)/p_Y(y)du

同理，对于固定的x，若p_X(x) > 0，则称：
p_{Y|X}(y|x) = p(x,y)/p_X(x)

为在X = x条件下Y的条件概率密度。

条件分布函数为：
F_{Y|X}(y|x) = P{Y ≤ y | X = x} = ∫[−∞,y] p_{Y|X}(v|x)dv = ∫[−∞,y] p(x,v)/p_X(x)dv

**例题**：对于二维正态分布(X,Y)~N(μ₁,μ₂,σ₁²,σ₂²,ρ)，其条件分布仍为正态分布：

X在Y = y条件下的条件分布为：N(μ₁ + ρ(σ₁/σ₂)(y-μ₂), σ₁²(1-ρ²))

Y在X = x条件下的条件分布为：N(μ₂ + ρ(σ₂/σ₁)(x-μ₁), σ₂²(1-ρ²))


## 第四章 随机变量的数字特征

### 第一节 数学期望

#### 一、数学期望的概念

数学期望（Mathematical Expectation）是概率论中最重要的数字特征之一，反映随机变量取值的平均趋势。

**1. 离散型随机变量的数学期望**

设离散型随机变量X的分布律为P{X = x_k} = p_k，k = 1,2,...，若级数∑|x_k|p_k绝对收敛，即∑|x_k|p_k < ∞，则称级数∑x_k p_k的和为随机变量X的数学期望，记为E(X)，即：
E(X) = ∑x_k p_k

**2. 连续型随机变量的数学期望**

设连续型随机变量X的分布密度为p(x)，若积分∫|x|p(x)dx绝对收敛，即∫|x|p(x)dx < ∞，则称∫xp(x)dx为随机变量X的数学期望，即：
E(X) = ∫xp(x)dx

#### 二、常见分布的数学期望

**离散型分布的数学期望**：
1. **0-1分布**：X ~ B(1,p)，E(X) = p
2. **二项分布**：X ~ B(n,p)，E(X) = np
3. **泊松分布**：X ~ P(λ)，E(X) = λ
4. **几何分布**：P{X = k} = p(1-p)^(k-1)，E(X) = 1/p

**连续型分布的数学期望**：
1. **均匀分布**：X ~ U(a,b)，E(X) = (a+b)/2
2. **正态分布**：X ~ N(μ,σ²)，E(X) = μ
3. **指数分布**：X ~ Exp(λ)，E(X) = 1/λ
4. **伽玛分布**：X ~ Γ(α,β)，E(X) = α/β

#### 三、随机变量函数的数学期望

**一维随机变量函数的数学期望**：
设X是一个随机变量，Y = f(X)，则
- 当X为离散型时：E[f(X)] = ∑f(x_k)p_k
- 当X为连续型时：E[f(X)] = ∫f(x)p(x)dx

**二维随机变量函数的数学期望**：
- 二维离散型：E[f(X,Y)] = ∑∑f(x_i,y_j)p_ij
- 二维连续型：E[f(X,Y)] = ∫∫f(x,y)p(x,y)dxdy

#### 四、数学期望的性质

1. **常数性质**：设C是常数，则E(C) = C
2. **常数因子**：设X是一个随机变量，C是常数，则E(CX) = CE(X)
3. **线性性质**：设X、Y是两个随机变量，则E(X+Y) = E(X) + E(Y)
4. **独立性性质**：设X、Y是相互独立的随机变量，则E(XY) = E(X)E(Y)

推广：E(∑a_i X_i) = ∑a_i E(X_i)

### 第二节 方差

#### 一、方差的概念

方差是衡量随机变量取值分散程度的数字特征。

**定义**：设X是一个随机变量，若E[X-E(X)]²存在，则称其为X的方差，记为D(X)或Var(X)，即：
D(X) = E[X-E(X)]²

标准差（均方差）：σ(X) = √D(X)

**方差的计算公式**：
D(X) = E[X-E(X)]² = E(X²) - [E(X)]²

#### 二、常见分布的方差

**离散型分布的方差**：
1. **0-1分布**：X ~ B(1,p)，D(X) = p(1-p)
2. **二项分布**：X ~ B(n,p)，D(X) = np(1-p)
3. **泊松分布**：X ~ P(λ)，D(X) = λ
4. **几何分布**：D(X) = (1-p)/p²

**连续型分布的方差**：
1. **均匀分布**：X ~ U(a,b)，D(X) = (b-a)²/12
2. **正态分布**：X ~ N(μ,σ²)，D(X) = σ²
3. **指数分布**：X ~ Exp(λ)，D(X) = 1/λ²

#### 三、方差的性质

1. **常数性质**：设C是常数，则D(C) = 0
2. **常数因子**：设X是一个随机变量，k是常数，则D(kX) = k²D(X)
3. **独立性性质**：设随机变量X、Y相互独立，且D(X)、D(Y)存在，则D(X±Y) = D(X) + D(Y)

推广：若X₁,X₂,...,Xₙ相互独立，则D(∑a_i X_i) = ∑a²_i D(X_i)

#### 四、切比谢夫不等式

设随机变量X具有数学期望E(X) = μ，方差D(X) = σ²，则对于任意正数ε，有：
P{|X-μ| ≥ ε} ≤ σ²/ε²
或 P{|X-μ| < ε} ≥ 1 - σ²/ε²

#### 五、矩的概念

**原点矩**：设X是一随机变量，若E(X^k)存在，则称其为X的k阶原点矩，记为a_k = E(X^k)

**中心矩**：若E[X-E(X)]^k存在，则称其为X的k阶中心矩，记为μ_k = E[X-E(X)]^k

- 一阶原点矩：a₁ = E(X)（数学期望）
- 二阶中心矩：μ₂ = E[X-E(X)]² = D(X)（方差）

### 第三节 协方差及相关系数

#### 一、协方差

**定义**：设(X,Y)是二维随机变量，称E[(X-E(X))(Y-E(Y))]为随机变量X与Y的协方差，记为cov(X,Y)或σ_xy，即：
cov(X,Y) = E[(X-E(X))(Y-E(Y))]

**协方差的计算公式**：
cov(X,Y) = E(XY) - E(X)E(Y)

**协方差的性质**：
1. cov(X,Y) = cov(Y,X)
2. cov(X,Y) = E(XY) - E(X)E(Y)
3. cov(aX,bY) = ab·cov(X,Y)
4. cov(X₁+X₂,Y) = cov(X₁,Y) + cov(X₂,Y)
5. 若X与Y独立，则cov(X,Y) = 0
6. D(X±Y) = D(X) + D(Y) ± 2cov(X,Y)

#### 二、相关系数

**定义**：称ρ_xy = cov(X,Y)/[√D(X)·√D(Y)]为随机变量X与Y的相关系数。

**相关系数的性质**：
1. |ρ_xy| ≤ 1
2. ρ_xy = 1的充要条件是存在常数a、b，使P{Y = aX + b} = 1
3. 若X与Y相互独立，则X与Y不相关（ρ_xy = 0），但反之不真

**不相关的充要条件**：
- ρ_xy = 0 ⇔ X与Y不相关
- cov(X,Y) = 0 ⇔ X与Y不相关
- E(XY) = E(X)E(Y) ⇔ X与Y不相关
- D(X+Y) = D(X) + D(Y) ⇔ X与Y不相关

#### 三、协方差矩阵

**n维随机变量协方差矩阵**：设n维随机变量(X₁,X₂,...,Xₙ)的二阶混合中心矩σ_ij = E[(X_i-E(X_i))(X_j-E(X_j))]都存在，则称矩阵
Σ = [σ_ij] = [σ₁₁ σ₁₂ ... σ₁ₙ; σ₂₁ σ₂₂ ... σ₂ₙ; ...; σₙ₁ σₙ₂ ... σₙₙ]
为n维随机变量的协方差矩阵。

协方差矩阵的性质：
1. 协方差矩阵是对称矩阵
2. 协方差矩阵是非负定矩阵


## 第五章 大数定律与中心极限定理

### 第一节 大数定律

#### 一、问题的提出

大数定律是概率论中用于研究大量随机现象中平均结果稳定性的理论。在第一章概率的统计定义中讲到，随机现象在大量重复试验中呈现明显的统计规律性，即事件发生的频率具有稳定性。伯努利于1713年首先提出关于频率稳定性的定理，被称为伯努利大数定律。

大数定律的客观背景：
- 大量抛掷硬币正面出现频率
- 生产过程中的废品率
- 字母使用频率
- 大量测量值的算术平均值也具有稳定性

#### 二、随机变量序列的收敛性

**1. 依分布收敛**
设随机变量序列{Y_n}(n=1,2,...)的分布函数分别为F_n(x)，和随机变量Y的分布函数为F(x)，若在F(x)的所有连续点x上都有lim[n→∞]F_n(x) = F(x)，则称随机变量序列{Y_n}依分布收敛于随机变量Y，简记为Y_n ⎯→⎯^L Y。

**2. 依概率收敛**
设随机变量序列{Y_n}(n=1,2,...)和随机变量Y，若对任意实数ε > 0，有lim[n→∞]P{|Y_n - Y| ≥ ε} = 0，或lim[n→∞]P{|Y_n - Y| < ε} = 1，则称随机变量序列{Y_n}依概率收敛于随机变量Y，简记为Y_n ⎯→⎯^P Y。

**3. r阶收敛**
设随机变量序列{Y_n}和随机变量Y对r > 0，若E|Y_n|^r < ∞ (n=1,2,...)和E|Y|^r < ∞，若lim[n→∞]E|Y_n - Y|^r = 0，则称随机变量序列{Y_n}r阶收敛于随机变量Y，简记为Y_n ⎯→⎯^r Y。

**4. 几乎处处收敛**
设随机变量序列{Y_n(ω)}和随机变量Y(ω)，若P{ω:lim[n→∞]Y_n(ω) = Y(ω)} = 1，或简记为P{lim[n→∞]Y_n = Y} = 1，则称随机变量序列{Y_n}以概率1（或几乎处处）收敛于随机变量Y，简记为Y_n ⎯→⎯^a.e. Y。

#### 三、常用的大数定律

**1. 切比谢夫大数定律**
设{X_n}是两两不相关的随机变量序列，每一随机变量都有有限的方差，并有公共的上界，即D(X_i) ≤ C (i = 1,2,...)，则对任意的ε > 0，有：
lim[n→∞]P{|(1/n)∑[i=1 to n]X_i - (1/n)∑[i=1 to n]E(X_i)| ≥ ε} = 0

**2. 伯努利大数定律**
设μ_n是n次独立重复伯努利试验中事件A发生的次数，设事件A在每次试验中发生的概率为p，则对任意的ε > 0，有：
lim[n→∞]P{|μ_n/n - p| ≥ ε} = 0

伯努利大数定律表明事件A发生的频率μ_n/n依概率收敛于事件的概率p，用严格的数学形式表达了频率的稳定性。

**3. 辛钦大数定律**
设{X_n}为独立同分布的随机变量序列，且具有数学期望E(X_i) = μ (i = 1,2,...)，则对任意的ε > 0，有：
lim[n→∞]P{|(1/n)∑[i=1 to n]X_i - μ| ≥ ε} = 0

即(1/n)∑[i=1 to n]X_i ⎯→⎯^P μ

### 第二节 中心极限定理

#### 一、问题的提出

由大数定律，我们得知满足一定条件的随机变量序列的算术平均值依概率收敛。在实际中，人们发现n个相互独立同分布的随机变量之和的分布近似于正态分布，并且n越大，近似程度越好。

中心极限定理是概率论中最重要的定理之一，它描述了大量微小的、独立的随机因素的总和的分布近似于正态分布。

#### 二、中心极限定理

**1. 林德贝格-列维中心极限定理**
设随机变量X₁, X₂, ..., Xₙ相互独立同分布，且具有数学期望与方差：
E(X_i) = μ, D(X_i) = σ² ≠ 0 (i = 1,2,...,n)

则随机变量Y_n* = (∑[i=1 to n]X_i - nμ)/(σ√n)的分布函数F_n(x)对于任意x满足：
lim[n→∞]F_n(x) = lim[n→∞]P{Y_n* ≤ x} = ∫[-∞,x]e^(-t²/2)dt/√(2π)

即当n → ∞时，Y_n*渐近服从标准正态分布，记为Y_n* ~ AN(0,1)。

**2. 棣莫佛-拉普拉斯定理**
设随机变量Y_n服从二项分布B(n,p)，则其标准化随机变量Y_n* = (Y_n - np)/√[np(1-p)]的分布函数F_n(x)的极限为：
lim[n→∞]P{(Y_n - np)/√[np(1-p)] ≤ x} = ∫[-∞,x]e^(-t²/2)dt/√(2π)

**3. 中心极限定理的总结**
- 设随机变量X₁, X₂, ..., Xₙ相互独立，且E(X_i) = μ, D(X_i) = σ²。
- 当n充分大时，随机变量Z_n = ∑[i=1 to n]X_i近似服从N(nμ, nσ²)。
- 当n充分大时，随机变量Z_n' = (1/n)∑[i=1 to n]X_i近似服从N(μ, σ²/n)。

中心极限定理的实际应用：
- 二项分布的正态近似：当np ≥ 5和n(1-p) ≥ 5时，二项分布可用正态分布近似。
- 一般情况下，当n ≥ 30时，中心极限定理的近似效果较好。

中心极限定理的重要意义在于，无论组成系统的基本随机变量具有什么样的分布，只要它们相互独立，并且个数充分大，那么由它们总和所构成的系统，都服从或近似服从正态分布。这解释了为什么正态分布在实际应用中如此常见。


## 第六章 样本及抽样分布

### 第一节 基本概念

#### 一、总体与个体

在统计学中，我们把研究对象的全体称为**总体**，组成总体的每一个单元称为**个体**。

- 总体：研究对象的全体
- 个体：组成总体的每一个单元
- 有限总体：个体数量有限的总体
- 无限总体：个体数量无限的总体

#### 二、样本与简单随机抽样

**定义**：从总体X中抽取的n个个体X₁, X₂, ..., Xₙ，如果满足：
1. X₁, X₂, ..., Xₙ相互独立
2. X₁, X₂, ..., Xₙ都与总体X同分布

则称X₁, X₂, ..., Xₙ为总体X的一个**简单随机样本**，简称**样本**，n称为**样本容量**。

**简单随机抽样的特点**：
- 代表性：样本中的每个个体都来自总体
- 独立性：样本中各个个体的抽取是相互独立的
- 同分布性：样本中各个个体与总体具有相同的分布

#### 三、统计量

**定义**：设X₁, X₂, ..., Xₙ是来自总体X的一个样本，g(X₁, X₂, ..., Xₙ)是样本的函数，若g中不含任何未知参数，则称g(X₁, X₂, ..., Xₙ)为一个**统计量**。

**常用统计量**：

1. **样本均值**：
$$\overline{X} = \frac{1}{n}\sum_{i=1}^{n}X_i$$

2. **样本方差**：
$$S^2 = \frac{1}{n-1}\sum_{i=1}^{n}(X_i - \overline{X})^2$$

3. **样本k阶原点矩**：
$$A_k = \frac{1}{n}\sum_{i=1}^{n}X_i^k$$

4. **样本k阶中心矩**：
$$B_k = \frac{1}{n}\sum_{i=1}^{n}(X_i - \overline{X})^k$$

5. **样本标准差**：
$$S = \sqrt{S^2} = \sqrt{\frac{1}{n-1}\sum_{i=1}^{n}(X_i - \overline{X})^2}$$

### 第二节 常用统计分布

#### 一、χ²分布（卡方分布）

**定义**：设X₁, X₂, ..., Xₙ相互独立，都服从标准正态分布N(0,1)，则称随机变量
$$\chi^2 = X_1^2 + X_2^2 + ... + X_n^2$$
服从自由度为n的χ²分布，记作χ² ~ χ²(n)。

**χ²分布的性质**：
1. **概率密度函数**：当x > 0时，
$$f(x) = \begin{cases}
\frac{1}{2^{n/2}\Gamma(n/2)}x^{n/2-1}e^{-x/2}, & x > 0 \\
0, & x \leq 0
\end{cases}$$

2. **数学期望**：E(χ²) = n

3. **方差**：D(χ²) = 2n

4. **可加性**：若χ₁² ~ χ²(n₁)，χ₂² ~ χ²(n₂)，且χ₁²与χ₂²独立，则χ₁² + χ₂² ~ χ²(n₁ + n₂)

**分位点**：对于给定的α (0 < α < 1)，若P{χ² > χ²α(n)} = α，则称χ²α(n)为χ²(n)分布的上α分位点。

#### 二、t分布（学生氏分布）

**定义**：设X ~ N(0,1)，Y ~ χ²(n)，且X与Y相互独立，则称随机变量
$$T = \frac{X}{\sqrt{Y/n}}$$
服从自由度为n的t分布，记作T ~ t(n)。

**t分布的概率密度函数**：
$$f(t) = \frac{\Gamma[(n+1)/2]}{\sqrt{n\pi}\Gamma(n/2)}\left(1+\frac{t^2}{n}\right)^{-(n+1)/2}, \quad -\infty < t < +\infty$$

**t分布的性质**：
1. 当n充分大时，t分布近似于标准正态分布
2. t分布的图形关于t = 0对称
3. E(T) = 0 (n > 1)
4. D(T) = n/(n-2) (n > 2)

**分位点**：对于给定的α (0 < α < 1)，若P{T > tα(n)} = α，则称tα(n)为t(n)分布的上α分位点。

#### 三、F分布

**定义**：设U ~ χ²(n₁)，V ~ χ²(n₂)，且U与V相互独立，则称随机变量
$$F = \frac{U/n_1}{V/n_2}$$
服从自由度为(n₁, n₂)的F分布，记作F ~ F(n₁, n₂)。

**F分布的性质**：
1. 若F ~ F(n₁, n₂)，则1/F ~ F(n₂, n₁)
2. 若T ~ t(n)，则T² ~ F(1, n)

**分位点**：对于给定的α (0 < α < 1)，若P{F > Fα(n₁, n₂)} = α，则称Fα(n₁, n₂)为F(n₁, n₂)分布的上α分位点。

且有：F₁-α(n₁, n₂) = 1/Fα(n₂, n₁)

### 第三节 抽样分布

#### 一、正态总体的样本均值和样本方差的分布

**定理1**：设X₁, X₂, ..., Xₙ是来自正态总体N(μ, σ²)的样本，则有：
1. 样本均值$$\overline{X} \sim N(\mu, \sigma^2/n)$$
2. 样本均值$$\overline{X}$$与样本方差$$S^2$$相互独立
3. $$\frac{(n-1)S^2}{\sigma^2} \sim \chi^2(n-1)$$

**定理2**（t分布的t统计量）：在定理1的条件下，
$$\frac{\overline{X}-\mu}{S/\sqrt{n}} \sim t(n-1)$$

#### 二、两个正态总体的抽样分布

设X₁, X₂, ..., Xₙ₁是来自正态总体N(μ₁, σ₁²)的样本，
Y₁, Y₂, ..., Yₙ₂是来自正态总体N(μ₂, σ₂²)的样本，
且两样本相互独立。

**定理3**：
1. $$\frac{\overline{X}-\overline{Y}-(\mu_1-\mu_2)}{\sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2}}} \sim N(0,1)$$
2. $$\frac{S_1^2/\sigma_1^2}{S_2^2/\sigma_2^2} \sim F(n_1-1, n_2-1)$$

**定理4**（两样本t统计量）：当σ₁² = σ₂² = σ²时，
$$\frac{(\overline{X}-\overline{Y})-(\mu_1-\mu_2)}{S_w\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}} \sim t(n_1+n_2-2)$$

其中$$S_w^2 = \frac{(n_1-1)S_1^2+(n_2-1)S_2^2}{n_1+n_2-2}$$称为合并方差。


## 第七章 参数估计

### 第一节 参数的点估计

#### 一、问题的提出

在实际问题中，总体X的分布函数$F(x;\theta)$的形式为已知，但参数$\theta$未知。设$X_1, X_2, ..., X_n$是X的一个样本，$x_1, x_2, ..., x_n$为相应的一个样本值。我们希望用样本值去估计未知参数$\theta$，这种问题称为参数估计问题。

**例1**：已知某电话局在单位时间内收到用户呼唤次数这个总体$X \sim P(\lambda)$，即X的分布律$P\{X=k\} = \frac{e^{-\lambda}\lambda^k}{k!} (k=0,1,2,...)$的形式已知，但参数$\lambda$未知，需要利用样本值估计$\lambda$的值。

**例2**：已知某种灯泡的寿命$X \sim N(\mu,\sigma^2)$，即X的分布密度$f(x;\mu,\sigma^2) = \frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}} (x \in (-\infty,+\infty))$的形式已知，但参数$\mu,\sigma^2$未知。利用样本值估计$\mu,\sigma^2$。

#### 二、矩估计法

矩估计法是由英国统计学家皮尔逊(K.Pearson)在1894年提出，基本思想是用样本的k阶原点矩$A_k = \frac{1}{n}\sum_{i=1}^{n}X_i^k$去估计总体的k阶原点矩$E(X^k)$，并由此得到未知参数的估计量。

**矩估计法的具体步骤**：
1. 求出$E(X^k) = \alpha_k(\theta_1, \theta_2, ..., \theta_m)$，$k=1,2,...,m$
2. 令$A_k = \alpha_k$，$k=1,2,...,m$
3. 解出$\hat{\theta_1}, \hat{\theta_2}, ..., \hat{\theta_m}$

**例3**：设总体$X \sim P(\lambda)$，求参数$\lambda$的矩估计量。
解：由于$E(X) = \lambda$，可得$\hat{\lambda} = \frac{1}{n}\sum_{i=1}^{n}X_i = \overline{X}$

**例4**：设总体$X \sim U[\theta_1, \theta_2]$，求参数$\theta_1, \theta_2$的矩估计量。
解：容易求得$E(X) = \frac{\theta_1+\theta_2}{2}$，$E(X^2) = \frac{\theta_1^2+\theta_1\theta_2+\theta_2^2}{3}$
故令$\overline{X} = \frac{\theta_1+\theta_2}{2}$，$\frac{1}{n}\sum_{i=1}^{n}X_i^2 = \frac{\theta_1^2+\theta_1\theta_2+\theta_2^2}{3}$
解得$\hat{\theta_1} = \overline{X} - \sqrt{3S_n^2}$，$\hat{\theta_2} = \overline{X} + \sqrt{3S_n^2}$

#### 三、最大似然估计

最大似然估计最初是由德国数学家高斯(Gauss)于1821年提出，英国统计学家费歇尔(R.A.Fisher)在1922年作了进一步发展，使之成为数理统计中最重要应用最广泛的方法之一。

**1. 似然函数**
设总体X的分布律为$P(X=x) = p(x;\theta)$或分布密度为$p(x;\theta)$，其中$\theta = (\theta_1, \theta_2, ..., \theta_m)$未知，$(X_1, X_2, ..., X_n)$为来自总体X的分布律(或分布密度)，当给定样本值$(x_1, x_2, ..., x_n)$后，似然函数为$L(\theta) = \prod_{i=1}^{n}p(x_i;\theta)$

**2. 最大似然估计的定义**
设总体X的分布密度(或分布律)为$p(x;\theta)$，其中$\theta = (\theta_1, \theta_2, ..., \theta_m)$为未知参数。又设$(x_1, x_2, ..., x_n)$是总体X的一个样本值，如果似然函数$L(\theta) = \prod_{i=1}^{n}p(x_i;\theta)$在$\hat{\theta} = (\hat{\theta_1}, \hat{\theta_2}, ..., \hat{\theta_m})$处达到最大，则称$\hat{\theta_1}, \hat{\theta_2}, ..., \hat{\theta_m}$分别为$\theta_1, \theta_2, ..., \theta_m$的最大似然估计量。

**3. 求最大似然估计量的一般步骤**：
1° 求似然函数$L(\theta)$；
2° 求出$\ln L(\theta)$及似然方程$\frac{\partial \ln L(\theta)}{\partial \theta_i} = 0$，$i=1,2,...,m$；
3° 解似然方程得到最大似然估计值；
4° 则最大似然估计量为（小写换大写）。

**例5**：设总体X服从泊松分布$P(\lambda)$，其中$\lambda$为未知参数，试求参数$\lambda$的最大似然估计量。
解：似然函数为$L(\lambda) = \prod_{i=1}^{n}\frac{e^{-\lambda}\lambda^{x_i}}{x_i!} = \frac{e^{-n\lambda}\lambda^{\sum_{i=1}^{n}x_i}}{\prod_{i=1}^{n}x_i!}$
取对数$\ln L(\lambda) = \sum_{i=1}^{n}x_i\ln\lambda - n\lambda - \sum_{i=1}^{n}\ln x_i!$
$\frac{d\ln L(\lambda)}{d\lambda} = \frac{1}{\lambda}\sum_{i=1}^{n}x_i - n = 0$
解得$\hat{\lambda} = \frac{1}{n}\sum_{i=1}^{n}x_i = \overline{X}$，所以$\lambda$的最大似然估计量为$\hat{\lambda} = \overline{X}$。

### 第二节 估计量的评价标准

#### 一、无偏性

设$\hat{\theta} = \hat{\theta}(X_1, X_2, ..., X_n)$是参数$\theta$的一个估计量，如果$E(\hat{\theta}) = \theta$，则称$\hat{\theta}$是$\theta$的无偏估计(量)。

如果$\hat{\theta_n} = \hat{\theta_n}(X_1, X_2, ..., X_n)$的一列估计量满足关系式$\lim_{n \to \infty}E(\hat{\theta_n}) = \theta$，则称$\hat{\theta_n}$是$\theta$的渐近无偏估计量。

**例1**：证明：样本均值$\overline{X}$是$\mu$的无偏估计。样本方差$S_n^{*2}$是$\sigma^2$的渐近无偏估计。修正样本方差$S^2$是$\sigma^2$的无偏估计。
证：$E(\overline{X}) = \mu$，$E(S_n^{*2}) = \frac{n-1}{n}\sigma^2$，$E(S^2) = \sigma^2$
所以，$\overline{X}$和$S^2$均为无偏估计量，而$\lim_{n \to \infty}E(S_n^{*2}) = \lim_{n \to \infty}\frac{n-1}{n}\sigma^2 = \sigma^2$
故$S_n^{*2}$是$\sigma^2$的渐近无偏估计。

#### 二、有效性

若对任意$\theta$的无偏估计量$\hat{\theta_1}$和$\hat{\theta_2}$，均有$D(\hat{\theta_1}) < D(\hat{\theta_2})$，则称$\hat{\theta_1}$比$\hat{\theta_2}$有效。

如果存在一个无偏估计量$\hat{\theta_0}$，使对$\theta$的任意无偏估计量$\hat{\theta}$，都有$D(\hat{\theta_0}) < D(\hat{\theta})$，则称$\hat{\theta_0}$是$\theta$的最小方差无偏估计(量)，缩写为MVUE。

#### 三、相合性（一致估计）

设$\hat{\theta_n} = \hat{\theta_n}(X_1, X_2, ..., X_n)$是未知参数$\theta$的估计序列，如果依概率收敛于$\theta$，即对任意$\varepsilon > 0$，有：$\lim_{n \to \infty}P\{|\hat{\theta_n} - \theta| \geq \varepsilon\} = 0$，则称$\hat{\theta_n}$是$\theta$的相合估计(或一致估计)。

**定理**：设$\hat{\theta_n}$是$\theta$的一个估计量，若$\lim_{n \to \infty}E(\hat{\theta_n}) = \theta$且$\lim_{n \to \infty}D(\hat{\theta_n}) = 0$，则$\hat{\theta_n}$是$\theta$的相合估计。

### 第三节 参数的区间估计

#### 一、基本概念

设总体$X \sim F(x;\theta)$，$\theta$为未知参数，$(X_1, X_2, ..., X_n)$是来自总体X的样本。如果存在两个统计量$\hat{\theta_1}(X_1, X_2, ..., X_n)$和$\hat{\theta_2}(X_1, X_2, ..., X_n)$（$\hat{\theta_1} < \hat{\theta_2}$），使得对于给定的$\alpha (0 < \alpha < 1)$，有$P\{\hat{\theta_1} \leq \theta \leq \hat{\theta_2}\} = 1-\alpha$，则称区间$[\hat{\theta_1}, \hat{\theta_2}]$为$\theta$的置信度为$1-\alpha$的置信区间。

#### 二、数学期望的置信区间

**1. 正态总体方差$\sigma^2$已知，求$\mu$的置信区间**
设$(X_1, X_2, ..., X_n)$是来自总体$X \sim N(\mu,\sigma^2)$的一个样本，则$U = \frac{\overline{X}-\mu}{\sigma/\sqrt{n}} \sim N(0,1)$
对于给定的置信度$1-\alpha$，有$P\{|U| \leq u_{\alpha/2}\} = 1-\alpha$
即$P\{\overline{X} - \frac{\sigma}{\sqrt{n}}u_{\alpha/2} \leq \mu \leq \overline{X} + \frac{\sigma}{\sqrt{n}}u_{\alpha/2}\} = 1-\alpha$
故$\mu$的置信度为$1-\alpha$的置信区间为$[\overline{X} - \frac{\sigma}{\sqrt{n}}u_{\alpha/2}, \overline{X} + \frac{\sigma}{\sqrt{n}}u_{\alpha/2}]$

**2. 正态总体方差$\sigma^2$未知，求$\mu$的置信区间**
设$(X_1, X_2, ..., X_n)$是来自总体$X \sim N(\mu,\sigma^2)$的一个样本，则$T = \frac{\overline{X}-\mu}{S/\sqrt{n}} \sim t(n-1)$
对于给定的置信度$1-\alpha$，有$P\{|T| \leq t_{\alpha/2}(n-1)\} = 1-\alpha$
故$\mu$的置信度为$1-\alpha$的置信区间为$[\overline{X} - \frac{S}{\sqrt{n}}t_{\alpha/2}(n-1), \overline{X} + \frac{S}{\sqrt{n}}t_{\alpha/2}(n-1)]$

#### 三、正态总体方差的区间估计

设$(X_1, X_2, ..., X_n)$是来自总体$X \sim N(\mu,\sigma^2)$的一个样本，$\mu$未知，求总体方差$\sigma^2$的区间估计。
统计量$\chi^2 = \frac{(n-1)S^{*2}}{\sigma^2} = \frac{\sum_{i=1}^{n}(X_i-\overline{X})^2}{\sigma^2} \sim \chi^2(n-1)$
对于给定的置信度$1-\alpha$，有$P\{\chi^2_{1-\alpha/2}(n-1) \leq \chi^2 \leq \chi^2_{\alpha/2}(n-1)\} = 1-\alpha$
故$\sigma^2$的置信度为$1-\alpha$的置信区间为$[\frac{(n-1)S^{*2}}{\chi^2_{\alpha/2}(n-1)}, \frac{(n-1)S^{*2}}{\chi^2_{1-\alpha/2}(n-1)}]$

#### 四、两个正态总体均值差的区间估计

设$(X_1, X_2, ..., X_n)$为第一个总体的样本，$(Y_1, Y_2, ..., Y_m)$为第二个总体的样本。

**1. $\sigma_1^2$和$\sigma_2^2$均为已知**
$\mu_1-\mu_2$的置信度为$1-\alpha$的置信区间为$[(\overline{X}-\overline{Y}) \pm u_{\alpha/2}\sqrt{\frac{\sigma_1^2}{n}+\frac{\sigma_2^2}{m}}]$

**2. $\sigma_1^2 = \sigma_2^2 = \sigma^2$但为未知**
$\mu_1-\mu_2$的置信度为$1-\alpha$的置信区间为$[(\overline{X}-\overline{Y}) \pm t_{\alpha/2}(n+m-2)S_w\sqrt{\frac{1}{n}+\frac{1}{m}}]$
其中$S_w^2 = \frac{(n-1)S_1^{*2}+(m-1)S_2^{*2}}{n+m-2}$

#### 五、两个正态总体方差比的区间估计

设$(X_1, X_2, ..., X_n)$为总体$X \sim N(\mu_1,\sigma_1^2)$的样本，$(Y_1, Y_2, ..., Y_m)$为总体$Y \sim N(\mu_2,\sigma_2^2)$的样本，求方差比$\sigma_1^2/\sigma_2^2$的区间估计。
统计量$F = \frac{S_1^{*2}/\sigma_1^2}{S_2^{*2}/\sigma_2^2} = \frac{S_1^{*2}}{S_2^{*2}} \cdot \frac{\sigma_2^2}{\sigma_1^2} \sim F(n-1,m-1)$
故$\sigma_1^2/\sigma_2^2$的置信度为$1-\alpha$的置信区间为$[\frac{S_1^{*2}}{S_2^{*2}} \cdot \frac{1}{F_{\alpha/2}(n-1,m-1)}, \frac{S_1^{*2}}{S_2^{*2}} \cdot \frac{1}{F_{1-\alpha/2}(n-1,m-1)}]$


## 第八章 假设检验

### 第一节 假设检验的基本概念

#### 一、假设检验的基本原理

假设检验就是一种统计推断方法，根据样本提供的信息对所提出的假设作出判断：是接受，还是拒绝。

**基本原理**：小概率推断原理，小概率事件（概率接近0的事件），在一次试验中，实际上可认为不会发生（这是人们长期积累起的普遍经验！）。

著名的英国统计学家Ronald Fisher把20分之1作为标准，也就是0.05，从此0.05或比0.05小的概率都被认为是小概率。

**基本思想方法**：采用概率性质的反证法：
1. 先提出假设H₀
2. 再根据一次抽样所得到的样本值进行计算。若导致小概率事件发生，就认为出现了不合理现象，则否定假设H₀；否则，接受假设H₀。

#### 二、假设检验的基本概念

**1. 显著性水平**
α = P{拒绝H₀ | H₀正确}，数α称为显著性水平。

**2. 检验统计量**
用于检验假设的统计量，称为检验统计量。

**3. 原假设与备择假设**
假设检验问题通常叙述为"检验H₀:H₁"或叙述为"在显著性水平α下，针对H₁检验H₀"。
- H₀称为原假设或零假设
- H₁称为备择假设

**4. 临界点与拒绝域**
- 拒绝域W₁：拒绝原假设H₀的所有样本值(x₁, x₂, ..., xₙ)所组成的集合
- 临界点（值）：将样本的所有可能取值范围（即样本空间）分为两个互不相交的部分，即原假设的拒绝域和接受域

#### 三、两类错误

**第Ⅰ类错误（弃真错误）**：当原假设H₀为真，观察值却落入拒绝域，而作出了拒绝H₀的判断，称为第Ⅰ类错误，这类错误是"以真为假"。
- 犯第Ⅰ类错误的概率就是显著性水平α
- α = P{拒绝原假设H₀ | H₀为真}

**第Ⅱ类错误（取伪错误）**：当原假设H₀不真，而观察值却落入接受域，从而作出了接受H₀的判断，称为第Ⅱ类错误，这类错误是"以假为真"。
- 犯第Ⅱ类错误的概率记为β
- β = P{接受H₀ | H₀不正确}

**两类错误的关系**：
1. 当样本容量n一定时，若减少犯第一类错误的概率，则犯第Ⅱ类错误的概率往往增大
2. 要使犯两类错误的概率都减小，除非增加样本容量

假设检验中人们普遍执行同一准则：首先控制弃真错误（α）。假设检验的基本法则以α为显著性水平就体现了这一原则。

#### 四、假设检验的一般步骤

1. 根据实际问题的要求，提出待检验的假设H₀及备择假设H₁
2. 选择适当的统计量，在H₀成立的条件下，确定它的概率分布
3. 给定检验水平α，确定临界值和拒绝域W₁
4. 根据样本观察值计算统计量的值
5. 判断统计量值是否落入拒绝域W₁内，作出拒绝或接受H₀的判断

### 第二节 正态总体均值与方差的假设检验

#### 一、单个总体参数的检验

**1. U检验法（σ²为已知，关于μ的检验）**

设X₁, X₂, ..., Xₙ是来自正态总体N(μ,σ²)的样本，σ²已知，检验步骤：

- **假设**：H₀: μ = μ₀，H₁: μ ≠ μ₀
- **取检验统计量**：U = (X̄ - μ₀)/(σ/√n) ~ N(0,1)（当H₀为真时）
- **给定显著水平α**：拒绝域：W₁ = {(x₁, x₂, ..., xₙ) | |u| ≥ u_{α/2}}
- **由样本值算出U的值u**
- **判断**：若u ∈ W₁，则拒绝H₀；若u ∉ W₁，则接受H₀

**2. t检验法（σ²为未知，关于μ的检验）**

设X₁, X₂, ..., Xₙ是来自正态总体N(μ,σ²)的样本，σ²未知，检验步骤：

- **假设**：H₀: μ = μ₀，H₁: μ ≠ μ₀
- **取检验统计量**：T = (X̄ - μ₀)/(S*/√n) ~ t(n-1)（当H₀为真时）
- **给定显著水平α**：拒绝域：W₁ = {(x₁, x₂, ..., xₙ) | |t| ≥ t_{α/2}(n-1)}
- **由样本值算出T的值t**
- **判断**：若t ∈ W₁，则拒绝H₀；若t ∉ W₁，则接受H₀

**3. χ²检验法（μ未知，关于σ²的检验）**

设X₁, X₂, ..., Xₙ是来自正态总体N(μ,σ²)的样本，μ未知，检验步骤：

- **假设**：H₀: σ² = σ₀²，H₁: σ² ≠ σ₀²
- **取检验统计量**：χ² = (n-1)S*²/σ₀² ~ χ²(n-1)（当H₀为真时）
- **给定显著水平α**：拒绝域：W₁ = {(x₁, x₂, ..., xₙ) | χ² ≤ χ²_{1-α/2}(n-1) 或 χ² ≥ χ²_{α/2}(n-1)}
- **由样本值算出χ²的值**
- **判断**：若χ² ∈ W₁，则拒绝H₀；若χ² ∉ W₁，则接受H₀

#### 二、两个总体参数的检验

**1. 已知方差时两个正态总体均值的检验（U检验法）**

设总体X ~ N(μ₁,σ₁²)，总体Y ~ N(μ₂,σ₂²)，X与Y独立，(X₁, X₂, ..., X_{n₁})来自总体X的样本，(Y₁, Y₂, ..., Y_{n₂})来自总体Y的样本。

- **假设**：H₀: μ₁ = μ₂，H₁: μ₁ ≠ μ₂
- **取检验统计量**：U = (X̄ - Ȳ)/√(σ₁²/n₁ + σ₂²/n₂) ~ N(0,1)（当H₀为真时）
- **给定显著性水平α**：拒绝域：W₁ = {(x₁, ..., x_{n₁}; y₁, ..., y_{n₂}) | |u| ≥ u_{α/2}}
- **判断**：若u ∈ W₁，则拒绝H₀；若u ∉ W₁，则接受H₀

**2. 未知方差时两个正态总体均值的检验（t检验法）**

设总体X与Y满足相互独立且方差相等（σ₁² = σ₂² = σ²，未知），检验步骤：

- **假设**：H₀: μ₁ = μ₂，H₁: μ₁ ≠ μ₂
- **取检验统计量**：T = (X̄ - Ȳ)/[S_w√(1/n₁ + 1/n₂)] ~ t(n₁ + n₂ - 2)
- 其中S_w² = [(n₁-1)S₁*² + (n₂-1)S₂*²]/(n₁ + n₂ - 2)
- **给定显著性水平α**：拒绝域：W₁ = {(x₁, ..., x_{n₁}; y₁, ..., y_{n₂}) | |t| ≥ t_{α/2}(n₁ + n₂ - 2)}
- **判断**：若t ∈ W₁，则拒绝H₀；若t ∉ W₁，则接受H₀

**3. 总体方差的检验（F检验法）**

设总体X ~ N(μ₁,σ₁²)，总体Y ~ N(μ₂,σ₂²)，X与Y独立。

- **假设**：H₀: σ₁² = σ₂²，H₁: σ₁² ≠ σ₂²
- **取检验统计量**：F = S₁*²/S₂*² ~ F(n₁-1, n₂-1)（当H₀为真时）
- **给定显著性水平α**：拒绝域：W₁ = {f | f ≤ F_{1-α/2}(n₁-1, n₂-1) 或 f ≥ F_{α/2}(n₁-1, n₂-1)}
- **判断**：若f ∈ W₁，则拒绝H₀；若f ∉ W₁，则接受H₀

